{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaysonSuarez/IA/blob/main/ChatBot_Psicologo_RoBERTa_%2B_GENERATIVE_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c169c99",
      "metadata": {
        "id": "2c169c99"
      },
      "source": [
        "# RoBERTa con InterTASS\n",
        "Debe descargar el Dataset del siguiente enlace: http://tass.sepln.org/2020/?page_id=74. El archivo .zip llamado: Task 1 - train and dev sets.\n",
        "\n",
        "Y para correr en colab, debe usarse la version que usa GPU para que pueda funcionar."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffd4c3ad",
      "metadata": {
        "id": "ffd4c3ad"
      },
      "source": [
        "## Paso 1: Instalación de librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87b549f",
      "metadata": {
        "id": "b87b549f"
      },
      "outputs": [],
      "source": [
        "!pip install transformers scikit-learn pandas -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "7k9_jQidNDa6"
      },
      "id": "7k9_jQidNDa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformers: Proporciona acceso a modelos pre-entrenados como RoBERTa, utilizados para el procesamiento del lenguaje natural.\n",
        "scikit-learn: Ofrece herramientas para el aprendizaje automático, incluyendo la codificación de etiquetas.\n",
        "pandas: Permite la manipulación y análisis de datos con estructuras de datos como DataFrames.\n",
        "--upgrade transformers: actualiza la librería transformers para que tengas la versión mas nueva"
      ],
      "metadata": {
        "id": "DLJfsidvRUyX"
      },
      "id": "DLJfsidvRUyX"
    },
    {
      "cell_type": "markdown",
      "id": "afed612c",
      "metadata": {
        "id": "afed612c"
      },
      "source": [
        "## Paso 2: Carga del dataset InterTASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145d0193",
      "metadata": {
        "id": "145d0193"
      },
      "outputs": [],
      "source": [
        "import zipfile, glob, pandas as pd\n",
        "\n",
        "zip_path = '/content/Task1-train-dev.zip'\n",
        "extract_dir = 'intertass'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(extract_dir)\n",
        "\n",
        "def load_split(split):\n",
        "    files = glob.glob(f\"{extract_dir}/{split}/*.tsv\")\n",
        "    dfs = []\n",
        "    for path in files:\n",
        "        country = path.split('/')[-1].split('.')[0]\n",
        "        df = pd.read_csv(path, sep='\\t', header=None, names=['id','text','label'])\n",
        "        df['country'] = country\n",
        "        dfs.append(df)\n",
        "    return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_train = load_split('train')\n",
        "df_dev   = load_split('dev')\n",
        "\n",
        "print(f\"Train: {df_train.shape[0]} muestras\")\n",
        "print(f\"Dev:   {df_dev.shape[0]} muestras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga el conjunto de datos InterTASS, que contiene texto etiquetado con emociones.\n",
        "\n",
        "Descarga un archivo zip que contiene los datos de entrenamiento y desarrollo (train/dev).\n",
        "Extrae los archivos del zip.\n",
        "Lee los archivos TSV (texto separado por tabulaciones) y los combina en un DataFrame de pandas.\n",
        "El resultado son dos DataFrames: df_train para entrenamiento y df_dev para desarrollo."
      ],
      "metadata": {
        "id": "yYWx_60sRpcK"
      },
      "id": "yYWx_60sRpcK"
    },
    {
      "cell_type": "markdown",
      "id": "f94a7502",
      "metadata": {
        "id": "f94a7502"
      },
      "source": [
        "## Paso 3: Exploración de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67a71991",
      "metadata": {
        "id": "67a71991"
      },
      "outputs": [],
      "source": [
        "print(df_train.head())\n",
        "print(df_train['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "df_train.head(): Muestra las primeras filas del DataFrame de entrenamiento para ver su estructura y contenido.\n",
        "df_train['label'].value_counts(): Cuenta la frecuencia de cada etiqueta de emoción en el conjunto de datos, lo que ayuda a comprender la distribución de las clases."
      ],
      "metadata": {
        "id": "R1klYmkjRzXv"
      },
      "id": "R1klYmkjRzXv"
    },
    {
      "cell_type": "markdown",
      "id": "50429d7c",
      "metadata": {
        "id": "50429d7c"
      },
      "source": [
        "## Paso 4: Preprocesamiento de texto y etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "217c71bf",
      "metadata": {
        "id": "217c71bf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_train['label_enc'] = le.fit_transform(df_train['label'])\n",
        "df_dev['label_enc']   = le.transform(df_dev['label'])\n",
        "print(dict(zip(le.classes_, le.transform(le.classes_))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepara los datos para ser utilizados por el modelo de aprendizaje automático.\n",
        "\n",
        "LabelEncoder: Convierte las etiquetas de texto (como \"joy\", \"sadness\") a valores numéricos (0, 1, 2, etc.). Esto es necesario porque muchos modelos de aprendizaje automático trabajan con datos numéricos."
      ],
      "metadata": {
        "id": "OB5AVHsGSBkp"
      },
      "id": "OB5AVHsGSBkp"
    },
    {
      "cell_type": "markdown",
      "id": "a43c0e7d",
      "metadata": {
        "id": "a43c0e7d"
      },
      "source": [
        "## Paso 5: Tokenización con RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13cdac60",
      "metadata": {
        "id": "13cdac60"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('BSC-TeMU/roberta-base-bne')\n",
        "def tokenize(df):\n",
        "    return tokenizer(\n",
        "        df['text'].tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='pt'\n",
        "    )\n",
        "train_enc = tokenize(df_train)\n",
        "dev_enc   = tokenize(df_dev)\n",
        "print(train_enc['input_ids'].shape, dev_enc['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convierte el texto en una secuencia de tokens (unidades básicas de significado) que el modelo RoBERTa pueda entender.\n",
        "\n",
        "AutoTokenizer: Carga un tokenizador pre-entrenado para RoBERTa.\n",
        "tokenize(): Aplica el tokenizador al texto de los DataFrames, convirtiéndolo en secuencias numéricas y añadiendo padding para que todas las secuencias tengan la misma longitud."
      ],
      "metadata": {
        "id": "lQcGooSqSI6o"
      },
      "id": "lQcGooSqSI6o"
    },
    {
      "cell_type": "markdown",
      "id": "e02aac83",
      "metadata": {
        "id": "e02aac83"
      },
      "source": [
        "## Paso 6: Fine-Tuning del modelo RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da4cf0b",
      "metadata": {
        "id": "0da4cf0b"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'BSC-TeMU/roberta-base-bne', num_labels=len(le.classes_)\n",
        ")\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    train_enc['input_ids'], train_enc['attention_mask'], torch.tensor(df_train['label_enc'].values)\n",
        ")\n",
        "dev_dataset   = torch.utils.data.TensorDataset(\n",
        "    dev_enc['input_ids'], dev_enc['attention_mask'],   torch.tensor(df_dev['label_enc'].values)\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    from sklearn.metrics import f1_score\n",
        "    return {\n",
        "        'accuracy': (preds == labels).mean(),\n",
        "        'f1_macro': f1_score(labels, preds, average='macro')\n",
        "    }\n",
        "\n",
        "class IntertassDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = IntertassDataset(train_enc, df_train['label_enc'].values)\n",
        "dev_dataset = IntertassDataset(dev_enc, df_dev['label_enc'].values)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=500,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Distribution of Labels in the Training Set\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(x='label', data=df_train)\n",
        "plt.title('Distribution of Labels in Training Set')\n",
        "plt.xlabel('Sentiment Label')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 2. Distribution of Labels in the Development Set\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(x='label', data=df_dev)\n",
        "plt.title('Distribution of Labels in Development Set')\n",
        "plt.xlabel('Sentiment Label')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 3. Text Length Analysis (optional - requires text length calculation)\n",
        "# Calculate the length of each text in the training set\n",
        "df_train['text_length'] = df_train['text'].apply(len)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df_train['text_length'], kde=True)\n",
        "plt.title('Distribution of Text Lengths in the Training Set')\n",
        "plt.xlabel('Text Length (Characters)')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rt86ScSTG4Jd"
      },
      "id": "Rt86ScSTG4Jd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrena el modelo RoBERTa para la tarea específica de análisis de sentimientos en el dataset InterTASS.\n",
        "\n",
        "AutoModelForSequenceClassification: Carga un modelo RoBERTa pre-entrenado y lo adapta para la clasificación de secuencias (en este caso, clasificar emociones).\n",
        "Trainer: Se encarga del proceso de entrenamiento, incluyendo la optimización de los parámetros del modelo.\n",
        "compute_metrics: Define las métricas que se usarán para evaluar el rendimiento del modelo durante el entrenamiento, como la precisión y la puntuación F1."
      ],
      "metadata": {
        "id": "d353ZVumSQZL"
      },
      "id": "d353ZVumSQZL"
    },
    {
      "cell_type": "markdown",
      "id": "c9b69360",
      "metadata": {
        "id": "c9b69360"
      },
      "source": [
        "## Paso 7: Evaluación y prueba de ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd58d05",
      "metadata": {
        "id": "1fd58d05"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "    enc = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    # Move the encoded input to the same device as the model\n",
        "    enc = {k: v.to(model.device) for k, v in enc.items()}\n",
        "    logits = model(**enc).logits\n",
        "    return le.inverse_transform([logits.argmax().item()])[0]\n",
        "\n",
        "\n",
        "while True:\n",
        "  user_input = input(\"Introduce el texto para predecir el sentimiento: \")\n",
        "  if user_input.lower() in [\"basta\", \"stop\", \"salir\", \"exit\", \"fin\", \"end\"]:\n",
        "    break\n",
        "  prediction = predict(user_input)\n",
        "  print(f\"El sentimiento predicho es: {prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Toma un texto como entrada, lo tokeniza, lo pasa por el modelo y devuelve la etiqueta de emoción predicha."
      ],
      "metadata": {
        "id": "6BMlw5f0Sibb"
      },
      "id": "6BMlw5f0Sibb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya que RoBERTa no es un LLM sino un Classifier, generamos un diccionario de posibles respuestas a las preguntas del user con el fin de:\n",
        "\n",
        "**1. Clasificar la emoción**\n",
        "\n",
        "**2. Analizar la emoción**\n",
        "\n",
        "**3. \"Generar\" respuestas segun la emoción clasificada**"
      ],
      "metadata": {
        "id": "DCFnjogdqPF3"
      },
      "id": "DCFnjogdqPF3"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Diccionario de respuestas según emoción\n",
        "respuestas = {\n",
        "    \"tristeza\": [\n",
        "        \"Lamento que te sientas así. Estoy aquí para escucharte.\",\n",
        "        \"Es normal sentirse triste a veces. ¿Quieres hablar más al respecto?\",\n",
        "        \"Tus emociones son válidas. No estás solo/a en esto.\",\n",
        "        \"Estoy aquí para ti. Cuéntame más si lo deseas.\",\n",
        "        \"La tristeza es una emoción humana. Permítete sentirla y expresarla.\"\n",
        "    ],\n",
        "    \"ansiedad\": [\n",
        "        \"Parece que estás experimentando ansiedad. Respirar profundamente puede ayudarte a calmarte.\",\n",
        "        \"La ansiedad puede ser abrumadora. Estoy aquí para apoyarte.\",\n",
        "        \"Recuerda que no estás solo/a. Hablar sobre lo que sientes puede aliviar la carga.\",\n",
        "        \"¿Hay algo específico que te preocupa? Compartirlo puede ayudarte a procesarlo.\",\n",
        "        \"La ansiedad es una respuesta natural al estrés. Juntos podemos encontrar formas de manejarla.\"\n",
        "    ],\n",
        "    \"ira\": [\n",
        "        \"Entiendo que te sientas enojado/a. Es importante reconocer esa emoción.\",\n",
        "        \"La ira puede ser una señal de que algo no está bien. ¿Quieres hablar sobre ello?\",\n",
        "        \"Tomarse un momento para respirar puede ayudar a manejar la ira.\",\n",
        "        \"Estoy aquí para escucharte sin juzgar. Cuéntame qué te ha molestado.\",\n",
        "        \"La ira es válida, pero encontrar formas saludables de expresarla es crucial.\"\n",
        "    ],\n",
        "    \"miedo\": [\n",
        "        \"El miedo es una emoción natural ante lo desconocido. Estoy aquí contigo.\",\n",
        "        \"Hablar sobre lo que te asusta puede disminuir su poder. ¿Quieres compartirlo?\",\n",
        "        \"Recuerda que eres fuerte y capaz de enfrentar tus temores.\",\n",
        "        \"No estás solo/a en esto. Juntos podemos encontrar maneras de afrontarlo.\",\n",
        "        \"Es valiente reconocer que sientes miedo. Estoy aquí para apoyarte.\"\n",
        "    ],\n",
        "    \"alegría\": [\n",
        "        \"¡Me alegra saber que te sientes bien! Comparte más sobre eso.\",\n",
        "        \"Es maravilloso que experimentes alegría. Disfruta el momento.\",\n",
        "        \"La alegría es contagiosa. Gracias por compartirla conmigo.\",\n",
        "        \"Celebremos juntos tu felicidad. ¿Qué te ha hecho sentir así?\",\n",
        "        \"Es genial escuchar noticias positivas. ¡Sigue compartiéndolas!\"\n",
        "    ],\n",
        "    \"sorpresa\": [\n",
        "        \"¡Vaya, eso suena inesperado! ¿Cómo te sientes al respecto?\",\n",
        "        \"Las sorpresas pueden ser emocionantes o desconcertantes. ¿Cuál fue tu reacción?\",\n",
        "        \"Cuéntame más sobre lo que te sorprendió. Estoy interesado/a en saber.\",\n",
        "        \"A veces, las sorpresas nos sacan de la rutina. ¿Fue una sorpresa agradable?\",\n",
        "        \"Es interesante cómo ocurren cosas inesperadas. ¿Cómo lo estás manejando?\"\n",
        "    ],\n",
        "    \"desagrado\": [\n",
        "        \"Entiendo que algo te ha causado desagrado. ¿Quieres hablar sobre ello?\",\n",
        "        \"Es importante reconocer lo que no nos agrada. Estoy aquí para escucharte.\",\n",
        "        \"Compartir lo que te molesta puede ayudarte a procesarlo.\",\n",
        "        \"Todos experimentamos desagrado en algún momento. No estás solo/a.\",\n",
        "        \"Hablar sobre lo que te incomoda puede ser liberador. ¿Te gustaría compartirlo?\"\n",
        "    ],\n",
        "    \"confianza\": [\n",
        "        \"Es genial que te sientas confiado/a. Esa es una emoción poderosa.\",\n",
        "        \"La confianza en uno mismo es clave para el bienestar. ¡Sigue así!\",\n",
        "        \"Me alegra saber que te sientes seguro/a. ¿Qué ha contribuido a eso?\",\n",
        "        \"La confianza puede abrir muchas puertas. ¿Hay algo que te gustaría compartir?\",\n",
        "        \"Es inspirador ver tu confianza. ¿Qué te ha llevado a sentirte así?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Función para obtener una respuesta empática\n",
        "def obtener_respuesta_emocional(emocion):\n",
        "    return random.choice(respuestas.get(emocion, [\"Estoy aquí para ti. Cuéntame más.\"]))\n"
      ],
      "metadata": {
        "id": "UVt1VlrgqMLP"
      },
      "id": "UVt1VlrgqMLP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polarity_to_possible_emotions = {\n",
        "    \"p\": [\"alegría\",\"sorpresa\"],       # Positive could relate to joy or surprise\n",
        "    \"n\": [\"tristeza\", \"miedo\", \"ansiedad\", \"ira\", \"desagrado\", \"frustrado\"], # Negative could relate to several negative emotions\n",
        "    \"neu\": [\"confianza\"]    # Neutral is harder to map; 'confianza' might fit some neutral contexts\n",
        "    # You could add 'none': [] or similar if your dataset includes 'NONE'\n",
        "}\n",
        "\n",
        "# Permitir al usuario ingresar texto y obtener una respuesta basada en la polaridad detectada\n",
        "while True:\n",
        "  user_input = input(\"¿Cómo te sientes hoy? (escribe 'salir' para terminar): \")\n",
        "  if user_input.lower() in [\"salir\", \"terminar\", \"adiós\"]:\n",
        "    print(\"¡Hasta luego!\")\n",
        "    break\n",
        "  if user_input:\n",
        "    try:\n",
        "      # Usar la función predict para obtener la POLARITY (P, N, NEU)\n",
        "      predicted_polarity = predict(user_input)\n",
        "      print(f\"La polaridad predicha es: {predicted_polarity.capitalize()}\")\n",
        "\n",
        "      # Convert the predicted polarity to lowercase\n",
        "      predicted_polarity_lower = predicted_polarity.lower()\n",
        "\n",
        "      # Get the list of possible emotions for this polarity\n",
        "      possible_emotions = polarity_to_possible_emotions.get(predicted_polarity_lower, []) # Default to empty list if polarity not found\n",
        "\n",
        "      respuesta = \"Entiendo. Estoy aquí para escucharte si quieres compartir más.\" # Default response if no matching emotion found\n",
        "\n",
        "      if possible_emotions:\n",
        "          # Pick one emotion randomly from the list of possible emotions for this polarity\n",
        "          # Ensure the chosen emotion is a key in the 'respuestas' dictionary before using it\n",
        "          valid_possible_emotions = [emo for emo in possible_emotions if emo in respuestas]\n",
        "\n",
        "          if valid_possible_emotions:\n",
        "              chosen_emotion = random.choice(valid_possible_emotions)\n",
        "              # Get a response for the chosen emotion using the original function\n",
        "              respuesta = obtener_respuesta_emocional(chosen_emotion)\n",
        "          # If possible_emotions list was not empty but none were valid keys in 'respuestas',\n",
        "          # we keep the default response defined above.\n",
        "\n",
        "      print(respuesta)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Ocurrió un error al procesar tu entrada: {e}\")\n",
        "      # Print the traceback to help diagnose the error if needed\n",
        "      import traceback\n",
        "      traceback.print_exc()\n",
        "  else:\n",
        "    print(\"Por favor, ingresa algo sobre cómo te sientes.\")"
      ],
      "metadata": {
        "id": "qNf0AzFavK6X"
      },
      "id": "qNf0AzFavK6X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere -q"
      ],
      "metadata": {
        "id": "6lrTCoU103nf"
      },
      "id": "6lrTCoU103nf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import random # Ensure random is imported if needed for the second loop (which it is for random.choice)\n",
        "import traceback # Ensure traceback is imported for error handling\n",
        "\n",
        "\n",
        "co = cohere.ClientV2('uGJ50Z2ilig2S60S5GbsIcIEwp1FdzosdkXkDsm8')\n",
        "\n",
        "print(\"\"\"-Recuerda que este chatbot es solo una herramienta de apoyo y no un sustituto de la ayuda profesional.\n",
        "Las respuestas que se generen son con fines de mejora y no deben ser consideradas como un diagnóstico o tratamiento profesional.-\"\"\")\n",
        "\n",
        "\n",
        "# Function to generate text using Cohere based on the detected emotion\n",
        "def generate_cohere_response(emotion, user_text):\n",
        "    prompt = f\"El usuario expresó un sentimiento de {emotion} con el texto: \\\"{user_text}\\\". Genera una respuesta empática y comprensiva en español basada en este sentimiento.\"\n",
        "\n",
        "    try:\n",
        "        response = co.chat(\n",
        "             model='command-a-03-2025',\n",
        "             messages=[\n",
        "                 {'role': 'system', 'content': f'Eres un chat únicamente entrenado para dar respuestas de ayuda psicológica, ninguna otra. Solo debes dar respuestas mejorativas, y no debes dar diagnósticos o tratamientos, ya que no eres un profesional. Responde de forma empática y comprensiva al usuario que expresó un sentimiento de {emotion} con el texto: \"{user_text}\".'},\n",
        "                 {'role': 'user', 'content': user_text}\n",
        "             ]\n",
        "         )\n",
        "        # Extract the text content from the response message\n",
        "        return response.message.content[0].text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Cohere response: {e}\")\n",
        "        return \"No pude generar una respuesta en este momento.\"\n",
        "\n",
        "# Modify the main loop to use Cohere for generation\n",
        "while True:\n",
        "  user_input = input(\"¿Cómo te sientes hoy? (escribe 'salir' para terminar): \")\n",
        "  if user_input.lower() in [\"salir\", \"terminar\", \"adiós\"]:\n",
        "    print(\"¡Hasta luego!\")\n",
        "    break\n",
        "  if user_input:\n",
        "    try:\n",
        "      predicted_polarity = predict(user_input)\n",
        "      print(f\"La polaridad predicha es: {predicted_polarity.capitalize()}\")\n",
        "\n",
        "      # Convert the predicted polarity to lowercase\n",
        "      predicted_polarity_lower = predicted_polarity.lower()\n",
        "\n",
        "      # Get the list of possible emotions for this polarity\n",
        "      possible_emotions = polarity_to_possible_emotions.get(predicted_polarity_lower, [])\n",
        "\n",
        "      respuesta = \"Entiendo. Estoy aquí para escucharte si quieres compartir más.\" # Default response\n",
        "\n",
        "      if possible_emotions:\n",
        "          # Pick one emotion randomly from the list of possible emotions for this polarity\n",
        "          valid_possible_emotions = [emo for emo in possible_emotions if emo in respuestas]\n",
        "\n",
        "          if valid_possible_emotions:\n",
        "              chosen_emotion = random.choice(valid_possible_emotions)\n",
        "              print(f\"(El chatbot interpretará esto como {chosen_emotion})\") # Optional: show the interpreted emotion\n",
        "              # Use Cohere to generate a response based on the chosen emotion and user text\n",
        "              respuesta = generate_cohere_response(chosen_emotion, user_input)\n",
        "      print(respuesta)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Ocurrió un error al procesar tu entrada: {e}\")\n",
        "      traceback.print_exc()\n",
        "  else:\n",
        "    print(\"Por favor, ingresa algo sobre cómo te sientes.\")"
      ],
      "metadata": {
        "id": "JIV0hMpzzo8G"
      },
      "id": "JIV0hMpzzo8G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Este código ya utiliza una forma Prompt Chaining\n",
        "El segundo bucle while utiliza la polaridad_prevista del modelo RoBERTa\n",
        "(que está entrenado en el conjunto de datos TASS) para determinar un conjunto potencial de emociones. A continuación, utiliza una emoción elegida al azar de ese conjunto, junto con la entrada original del usuario, como parte de la solicitud de la API Cohere para generar una respuesta más matizada y contextualmente relevante.\n",
        "\n",
        "# El código actual ya demuestra una cadena simple:\n",
        "Entrada del Usuario -> Predicción RoBERTa (Polaridad) -> Asignar Polaridad a Posibles Emociones -> Elegir Emoción -> Mensaje Cohere -> Respuesta Cohere.\n"
      ],
      "metadata": {
        "id": "AaPHFm_O3YgP"
      },
      "id": "AaPHFm_O3YgP"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}